                            4.5. Entendendo os problemas de codificação/decodificação

    Apesar de existir uma exceção genérica, UnicodeError, o erro relatado pelo Python em geral é mais
específico: ou é um UnicodeEncodeError (ao converter uma str para sequências binárias) ou é um
UnicodeDecodeError (ao ler uma sequência binária para uma str). Carregar módulos do Python também pode
geram um SyntaxError, quando a codificação da fonte for inesperada.


            **  A primeira coisa a observar quando aparece um erro de Unicode é o
                tipo exato da exceção. É um UnicodeEncodeError, um UnicodeDecodeError,
                ou algum outro erro (por exemplo, SyntaxError) mencionando um problema
                de codificação? Para resolver o problema, você primeiro precisa entendê-lo.





            # Tratando o UnicodeEncodeError


    A maioria dos codecs não-UTF entendem apenas um pequeno subconjunto dos caracteres Unicode. Ao
converter texto para bytes, um UnicodeEncodeError será gerado se um caractere não estiver definido
na codificação alvo, a menos que seja fornecido um tratamento especial, passando um argumento
errors para o método ou função de codificação. O comportamento para tratamento de erro é apresentado
no Exemplo:


-----------------------------------------------------------------------------------
Exemplo: Encoding to bytes: success and error handling
-----------------------------------------------------------------------------------
>>> city = 'São Paulo'
>>> city.encode('utf_8')  (1)
b'S\xc3\xa3o Paulo'
>>> city.encode('utf_16')
b'\xff\xfeS\x00\xe3\x00o\x00 \x00P\x00a\x00u\x00l\x00o\x00'
>>> city.encode('iso8859_1')  (2)
b'S\xe3o Paulo'
>>> city.encode('cp437')  (3)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/.../lib/python3.4/encodings/cp437.py", line 12, in encode
    return codecs.charmap_encode(input,errors,encoding_map)
UnicodeEncodeError: 'charmap' codec can't encode character '\xe3' in
position 1: character maps to <undefined>
>>> city.encode('cp437', errors='ignore')  (4)
b'So Paulo'
>>> city.encode('cp437', errors='replace')  (5)
b'S?o Paulo'
>>> city.encode('cp437', errors='xmlcharrefreplace')  (6)
b'S&#227;o Paulo'
-----------------------------------------------------------------------------------
    1.As codificações UTF lidam com qualquer str
    2.iso8859_1 também funciona com a string 'São Paulo'.
    3.cp437 não consegue codificar o 'ã' ("a" com til). O método default de tratamento
        de erro, — 'strict'—gera um UnicodeEncodeError.
    4.O método de tratamento errors='ignore' pula os caracteres que não podem ser
        codificados; isso normalmente é uma péssima ideia, levando a perda silenciosa
        de informação.
    5.Ao codificar, errors='replace' substitui os caracteres não-codificáveis por
        um '?'; aqui também há perda de informação, mas os usuários recebem um alerta
        de que algo está faltando.
    6.'xmlcharrefreplace' substitui os caracteres não-codificáveis por uma entidade
    XML. Se você não pode usar UTF e não pode perder informação, essa é a única opção.





            # Tratando o UnicodeDecodeError


    Nem todo byte contém um caractere ASCII válido, e nem toda sequência de bytes é um texto
codificado em UTF-8 ou UTF-16 válidos; assim, se você presumir uma dessas codificações ao
converter um sequência binária para texto, pode receber um UnicodeDecodeError, se bytes
inesperados forem encontrados.


    Por outro lado, várias codificações de 8 bits antigas, como a 'cp1252', a 'iso8859_1' e
a 'koi8_r' são capazes de decodificar qualquer série de bytes, incluindo ruído aleatório, sem
reportar qualquer erro.
        ->   Portanto, se seu programa presumir a codificação de 8 bits errada,
            ele vai decodificar lixo silenciosamente.


                **  Caracteres truncados ou distorcidos são conhecidos como "gremlins" ou
                    "mojibake" (文字化け—"texto modificado" em japonês).


    O Exemplo ilustra a forma como o uso do codec errado pode produzir gremlins ou
um UnicodeDecodeError.


------------------------------------------------------------------------------------
Exemplo:  Decodificando de str para bytes: sucesso e tratamento de erro
------------------------------------------------------------------------------------
>>> octets = b'Montr\xe9al'  (1)
>>> octets.decode('cp1252')  (2)
'Montréal'
>>> octets.decode('iso8859_7')  (3)
'Montrιal'
>>> octets.decode('koi8_r')  (4)
'MontrИal'
>>> octets.decode('utf_8')  (5)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 5:
invalid continuation byte
>>> octets.decode('utf_8', errors='replace')  (6)
'Montr�al'
------------------------------------------------------------------------------------
    1.A palavra "Montréal" codificada em latin1; '\xe9' é o byte para "é".
    2.Decodificar com Windows 1252 funciona, pois esse codec é um superconjunto de latin1.
    3.ISO-8859-7 foi projetado para a língua grega, então o byte '\xe9' é interpretado de
        forma incorreta, e nenhum erro é gerado.
    4.KOI8-R é foi projetado para o russo. Agora '\xe9' significa a letra "И" do alfabeto
        cirílico.
    5.O codec 'utf_8' detecta que octets não é UTF-8 válido, e gera um UnicodeDecodeError.
    6.Usando 'replace' para tratamento de erro, o \xe9 é substituído por "�" (ponto de
        código #U+FFFD), o caractere oficial do Unicode chamado REPLACEMENT CHARACTER,
        criado exatamente para representar caracteres desconhecidos.





            # O SyntaxError ao carregar módulos com codificação inesperada

    UTF-8 é a codificação default para fontes no Python 3, da mesma forma que ASCII era o default
no Python 2. Se você carregar um módulo .py contendo dados que não estejam em UTF-8, sem
declaração codificação, receberá uma mensagem como essa:

-------------------------------------------------------------------------------------
SyntaxError: Non-UTF-8 code starting with '\xe1' in file ola.py on line
  1, but no encoding declared; see https://python.org/dev/peps/pep-0263/
  for details
-------------------------------------------------------------------------------------

    Como o UTF-8 está amplamente instalado em sistemas GNU/Linux e macOS, um cenário onde isso tem
mais chance de ocorrer é na abertura de um arquivo .py criado no Windows, com cp1252. Observe que
esse erro ocorre mesmo no Python para Windows, pois a codificação default para fontes de Python 3
é UTF-8 em todas as plataformas.

    Para resolver esse problema, acrescente o comentário mágico coding no início do arquivo, como
no Exemplo:

------------------------------------------------------------------------
Exemplo 7. 'ola.py': um "Hello, World!" em português
# coding: cp1252

print('Olá, Mundo!')
------------------------------------------------------------------------




            # Como descobrir a codificação de uma sequência de bytes


    Como descobrir a codificação de uma sequência de bytes? Resposta curta: não é possível. Você
precisa ser informado.

    Alguns protocolos de comunicação e formatos de arquivo, como o HTTP e o XML, contêm cabeçalhos
que nos dizem explicitamente como o conteúdo está codificado. Você pode ter certeza que algumas
sequências de bytes não estão em ASCII, pois elas contêm bytes com valores acima de 127, e o modo
como o UTF-8 e o UTF-16 são construídos também limita as sequências de bytes possíveis.

